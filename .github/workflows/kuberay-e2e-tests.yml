name: Test KubeRay Operator E2E Tests

on:
  repository_dispatch:
    types: [branch-dispatch-e2e-post-merge]

jobs:
  run_kuberay_post_merge_e2e_tests:
    runs-on: kuberay-testing # target runner
    permissions:
      contents: read
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Clone KubeRay repository
        run: |
          git clone --depth=1 --branch dev https://github.com/opendatahub-io/kuberay.git

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          cache: false
          go-version: '1.24'

      - name: Set up gotestfmt
        uses: gotesttools/gotestfmt-action@v2
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install gotestsum
        run: go install gotest.tools/gotestsum@latest

      - name: Setup Kind Cluster with KubeRay Helm Repo
        uses: ./.github/actions/setup-kind-cluster

      - name: Deploy Kuberay operator
        id: deploy
        run: |
          echo "Deploying Kuberay operator"
          cd kuberay/ray-operator

          IMG=quay.io/opendatahub/kuberay-operator:dev
          make docker-build -e IMG="${IMG}" -e ENGINE=docker
          kind load docker-image ${IMG}

          make deploy -e IMG="${IMG}"
          kubectl wait --timeout=90s --for=condition=Available=true deployment -n default kuberay-operator

      - name: Update resource requirements for e2e tests
        if: steps.deploy.outcome == 'success'
        run: |
          echo "Updating resource requirements using Go AST manipulation..."
          cd kuberay/scripts
          go build -o update-resources update-resources.go
          ./update-resources -scenario pr ../ray-operator/test/e2e/support.go
          echo "Resource requirements updated successfully for e2e tests."

      - name: Start operator monitoring
        if: steps.deploy.outcome == 'success'
        run: |
          # Start background monitoring of operator and namespaces
          {
            echo "Starting operator monitoring..."
            while true; do
              echo "=== $(date) ==="
              echo "Operator pods:"
              kubectl get pods -n default -l app.kubernetes.io/name=kuberay-operator -o wide || true
              echo "Namespaces:"
              kubectl get namespaces | grep -E "(Terminating|test-|ray-)" || echo "No test/ray namespaces found"
              echo "RayCluster count:"
              kubectl get raycluster -A --no-headers 2>/dev/null | wc -l || echo "0"
              echo "RayJob count:"
              kubectl get rayjob -A --no-headers 2>/dev/null | wc -l || echo "0"
              echo "---"
              sleep 30
            done
          } > ./operator-monitoring.log 2>&1 &
          echo $! > ./monitor-pid.txt
          echo "Operator monitoring started with PID $(cat ./monitor-pid.txt)"

      - name: Run e2e tests (excluding TestRayJobRecovery) - First attempt
        if: steps.deploy.outcome == 'success'
        id: first_run
        continue-on-error: true
        run: |
          export KUBERAY_TEST_TIMEOUT_SHORT=5m KUBERAY_TEST_TIMEOUT_MEDIUM=12m KUBERAY_TEST_TIMEOUT_LONG=15m KUBERAY_TEST_RAY_IMAGE=rayproject/ray:2.52.1

          set -euo pipefail
          cd kuberay/ray-operator
          go test -timeout 120m -v ./test/e2e -skip "TestRayJobRecovery" -json 2>&1 | tee ./gotest.log | gotestfmt

      - name: Extract failed tests and retry
        if: steps.deploy.outcome == 'success' && steps.first_run.outcome == 'failure'
        run: |
          export KUBERAY_TEST_TIMEOUT_SHORT=5m KUBERAY_TEST_TIMEOUT_MEDIUM=12m KUBERAY_TEST_TIMEOUT_LONG=15m KUBERAY_TEST_RAY_IMAGE=rayproject/ray:2.52.1

          cd kuberay/ray-operator
          
          # Extract failed test names from the JSON output
          # Only get the most specific failed tests (subtests, not parent tests)
          all_failed_tests=$(grep -E '"Action":"(fail|skip)"' ./gotest.log | jq -r 'select(.Test != null and .Test != "") | .Test' | grep -v '^null$' | sort -u)
          
          # Filter to get only the most specific tests (those with "/" are subtests)
          # If a subtest failed, don't include its parent test
          failed_tests=""
          while IFS= read -r test; do
            if [[ "$test" == *"/"* ]]; then
              # This is a subtest, include it
              if [ -n "$failed_tests" ]; then
                failed_tests="$failed_tests"$'\n'"$test"
              else
                failed_tests="$test"
              fi
            else
              # This is a parent test, only include if no subtests of it are already included
              parent_has_subtest=false
              while IFS= read -r existing_test; do
                if [[ "$existing_test" == "$test/"* ]]; then
                  parent_has_subtest=true
                  break
                fi
              done <<< "$failed_tests"
              
              if [ "$parent_has_subtest" = false ]; then
                if [ -n "$failed_tests" ]; then
                  failed_tests="$failed_tests"$'\n'"$test"
                else
                  failed_tests="$test"
                fi
              fi
            fi
          done <<< "$all_failed_tests"
          
          if [ -n "$failed_tests" ]; then
            echo "Found failed tests:"
            echo "$failed_tests"
            
            # Create a regex pattern that matches the exact failed tests
            failed_pattern=""
            while IFS= read -r test; do
              if [ -n "$failed_pattern" ]; then
                failed_pattern="$failed_pattern|"
              fi
              # Escape the test name for regex and ensure exact match
              escaped_test=$(echo "$test" | sed 's/[[\.*^$()+?{|]/\\&/g')
              failed_pattern="$failed_pattern^${escaped_test}$"
            done <<< "$failed_tests"
            
            echo "Retry pattern: $failed_pattern"
            echo "Retrying failed tests..."
            
            # Use gotestsum approach similar to opendatahub-io/kuberay run-tests.sh
            # Create a regex pattern that matches only the specific failed tests
            # Extract unique parent test names (before the "/") for failed subtests
            parent_tests=""
            while IFS= read -r test; do
              if [[ "$test" == *"/"* ]]; then
                # Extract parent test name
                parent_test="${test%%/*}"
                if [[ "$parent_tests" != *"$parent_test"* ]]; then
                  if [ -n "$parent_tests" ]; then
                    parent_tests="$parent_tests|$parent_test"
                  else
                    parent_tests="$parent_test"
                  fi
                fi
              else
                # This is already a parent test
                if [[ "$parent_tests" != *"$test"* ]]; then
                  if [ -n "$parent_tests" ]; then
                    parent_tests="$parent_tests|$test"
                  else
                    parent_tests="$test"
                  fi
                fi
              fi
            done <<< "$failed_tests"
            
            # Create exact match pattern like in run-tests.sh
            if [[ "$parent_tests" == *"|"* ]]; then
              # Multiple tests - create pattern like ^(TestA|TestB)$
              retry_pattern="^($parent_tests)$"
            else
              # Single test - create pattern like ^TestA$
              retry_pattern="^$parent_tests$"
            fi
            
            echo "Retry pattern: $retry_pattern"
            echo "Retrying failed tests using gotestsum..."
            
            # Use gotestsum like in the opendatahub-io/kuberay script
            set -euo pipefail
            gotestsum --format standard-verbose -- -timeout 120m -run "$retry_pattern" ./test/e2e -p 1 -parallel 1 -json 2>&1 | tee ./gotest-retry.log
          else
            echo "No specific failed tests found, but first run failed. This might be a setup/teardown issue."
            exit 1
          fi

      - name: Capture KubeRay operator status and logs
        if: steps.deploy.outcome == 'success'
        run: |
          echo "=== KubeRay Operator Status ==="
          kubectl get pods -n default -l app.kubernetes.io/name=kuberay-operator -o wide | tee ./kuberay-operator-status.log
          kubectl describe pods -n default -l app.kubernetes.io/name=kuberay-operator | tee ./kuberay-operator-describe.log
          
          echo "=== KubeRay Operator Logs (Current) ==="
          kubectl logs -n default -l app.kubernetes.io/name=kuberay-operator --tail=1000 | tee ./kuberay-operator-current.log
          
          echo "=== KubeRay Operator Logs (Previous - if restarted) ==="
          kubectl logs -n default -l app.kubernetes.io/name=kuberay-operator --previous --ignore-errors=true | tee ./kuberay-operator-previous.log || echo "No previous logs available"
          
          echo "=== All KubeRay Operator Logs (All containers) ==="
          for pod in $(kubectl get pods -n default -l app.kubernetes.io/name=kuberay-operator -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Logs for pod: $pod ---" | tee -a ./kuberay-operator-all.log
            kubectl logs -n default "$pod" --all-containers=true --ignore-errors=true | tee -a ./kuberay-operator-all.log || echo "Failed to get logs for $pod"
            echo "--- Previous logs for pod: $pod ---" | tee -a ./kuberay-operator-all.log
            kubectl logs -n default "$pod" --all-containers=true --previous --ignore-errors=true | tee -a ./kuberay-operator-all.log || echo "No previous logs for $pod"
          done

      - name: Print debug info and capture namespace issues
        if: failure()
        run: |
          echo "=== Node Information ==="
          kubectl describe nodes | tee ./debug-nodes.log
          
          echo "=== Namespace Status ==="
          kubectl get namespaces -o wide | tee ./debug-namespaces.log
          
          echo "=== Terminating Namespaces Details ==="
          kubectl get namespaces --field-selector=status.phase=Terminating -o yaml | tee ./debug-terminating-namespaces.log
          
          echo "=== All Pods Status ==="
          kubectl get pods -A -o wide | tee ./debug-pods.log
          
          echo "=== RayCluster Resources ==="
          kubectl get raycluster -A -o yaml | tee ./debug-raycluster.log
          
          echo "=== RayJob Resources ==="
          kubectl get rayjob -A -o yaml | tee ./debug-rayjob.log
          
          echo "=== Events (Recent) ==="
          kubectl get events --sort-by='.lastTimestamp' -A | tail -100 | tee ./debug-events.log
          
          echo "=== KubeRay Operator Final Status ==="
          kubectl get pods -n default -l app.kubernetes.io/name=kuberay-operator -o wide | tee ./debug-operator-final-status.log
          kubectl describe pods -n default -l app.kubernetes.io/name=kuberay-operator | tee ./debug-operator-final-describe.log

      - name: Stop operator monitoring
        if: always()
        run: |
          if [ -f ./monitor-pid.txt ]; then
            monitor_pid=$(cat ./monitor-pid.txt)
            echo "Stopping operator monitoring (PID: $monitor_pid)"
            kill $monitor_pid 2>/dev/null || echo "Monitor process already stopped"
            sleep 2
          fi

      - name: Upload comprehensive logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: kuberay-e2e-logs
          retention-days: 10
          path: |
            **/*.log
            **/gotest*.log
            ./kuberay-operator-*.log
            ./debug-*.log
            ./operator-monitoring.log

      - name: Cleanup Kind Cluster
        if: always()
        uses: ./.github/actions/cleanup-kind-cluster
